A collection of simple python scripts examining the numerous hyperparameters of deep neural networks. The tutorials are
self-contained exploring one aspect at a time of how to tune deep neural networks to get better learning, generalization
and prediction performance.

The tutorials stem from the eBook: Jason Brownlee, *Better Deep Learning*, Machine Learning Mastery,
Available from https://machinelearningmastery.com/better-deep-learning/, accessed January 25th, 2019.

The contribution of this repository is the extensions of the tutorials to further explore and discuss a given topic.

The tutorials are divided into three parts:

**Better Learning**. Discover the techniques to improve and accelerate the process used to learn or optimize the weights
of a neural network model.

**Better Generalization**. Discover the techniques to reduce overfitting of the training dataset and improve the
generalization of models on new data.

**Better Predictions**. Discover the techniques to improve the performance of final models when used to make predictions
on new data.

## Better Learning

### Configure Capacity with Nodes and Layers
[Go to code samples and discussion of the extensions](02_configure_capacity_with_nodes_and_layers)

### Configure Gradient Precision with Batch Size
[Go to code samples and discussion of the extensions](03_conﬁgure_gradient_precision_with_batch_size)

### Configure What to Optimize with Loss Functions
[Go to code samples and discussion of the extensions](04_conﬁgure_what_to_optimize_with_loss_functions)

### Configure Speed of Learning with Learning Rate
[Go to code samples and discussion of the extensions](05_configure_speed_of_learning_with_learning_rate)

### Stabilize Learning with Data Scaling
[Go to code samples and discussion of the extensions](06_stabilize_learning_with_data_scaling)

### Fix Vanishing Gradients with ReLU
[Go to code samples and discussion of the extensions](07_fix_vanishing_gradients_with_relu)

### Fix Exploding Gradients with Gradient Clipping
[Go to code samples and discussion of the extensions](08_fix_exploding_gradients_with_gradient_clipping)

### Accelerate Learning with Batch Normalization
[Go to code samples and discussion of the extensions](09_accelerate_learning_with_batch_normalization)

### Deeper Models with Greedy Layer-Wise Pretraining
[Go to code samples and discussion of the extensions](10_deeper_models_with_greedy_layer_wise_pretraining)

### Jump-Start Training with Transfer Learning
[Go to code samples and discussion of the extensions](11_jump_start_training_with_transfer_learning)

## Better Generalization

### Penalize Large Weights with Weight Regularization
[Go to code samples and discussion of the extensions](13_penalize_large_weights_with_weight_regularization)

### Sparse Representations with Activity Regularization
[Go to code samples and discussion of the extensions](14_sparse_representations_with_activity_regularization)

### Force Small Weights with Weight Constraints
[Go to code samples and discussion of the extensions](15_force_small_weights_with_weight_constraints)

### Decouple Layers with Dropout
[Go to code samples and discussion of the extensions](16_decouple_layers_with_dropout)

### Promote Robustness with Noise
[Go to code samples and discussion of the extensions](17_promote_robustness_with_noise)

### Halt Training at the Right Time with Early Stopping
[Go to code samples and discussion of the extensions](18_halt_training_at_the_right_time_with_early_stopping)

## Better Predictions

### Combine Models From Multiple Runs with Model Averaging Ensemble
[Go to code samples and discussion of the extensions](20_combine_models_from_multiple_runs_with_model_averaging_ensemble)

### Contribute Proportional to Trust with Weighted Average Ensemble
[Go to code samples and discussion of the extensions](21_contribute_proportional_to_trust_with_weighted_average_ensemble)

### Fit Models on Different Samples with Resampling Ensembles
[Go to code samples and discussion of the extensions](22_fit_models_on_different_samples_with_resampling_ensembles)

### Models from Contiguous Epochs with Horizontal Voting Ensembles
[Go to code samples and discussion of the extensions](23_models_from_contiguous_epochs_with_horizontal_voting_ensembles)
